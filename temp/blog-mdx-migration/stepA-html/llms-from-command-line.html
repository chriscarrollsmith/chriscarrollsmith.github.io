<p>I recently had the pleasure of presenting at DevFest DC, where I demonstrated how to use Simon Willison's <a href="https://llm.datasette.io/">LLM tool</a> to interact with large language models directly from the command line. The presentation was filmed by Agora Media and shared by OpenHub.</p><div class="video-container" style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden;max-width:100%;margin:1.5rem 0;"><iframe style="position:absolute;top:0;left:0;width:100%;height:100%;" src="https://www.youtube.com/embed/XqJ6TVVA3Xw" title="LLMs from the Command Line - DevFest DC" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div><h2>What is LLM?</h2><p>Unlike agentic tools like Claude Code or Open Code that drive your terminal for you, LLM is a higher-touch tool that keeps you in the driver's seat. You make individual calls to LLMs to accomplish specific tasks while maintaining control of your workflow.</p><h2>Key Topics Covered</h2><ul><li><strong>Installation with UV</strong> - Using the modern Python package manager to install LLM in isolated environments, avoiding dependency conflicts</li><li><strong>Model Plugins</strong> - Installing plugins for different providers like DeepSeek and OpenRouter (which offers free model access)</li><li><strong>Templates</strong> - Creating reusable system prompts, like a Linux command-line copilot that provides context-aware help</li><li><strong>Whole-Repository Q&amp;A</strong> - Using RepoMix to pack codebases into AI-ready formats for comprehensive codebase analysis</li><li><strong>Progress Reporting</strong> - Generating visual SVG reports from git logs for client updates</li><li><strong>Structured Data Extraction</strong> - Using curl and LLM to scrape websites and extract JSON data with defined schemas</li><li><strong>Embeddings and Semantic Search</strong> - Building RAG pipelines with just a few commands for fuzzy searching across text corpora</li></ul><h2>Practical Applications</h2><p>The presentation demonstrates chaining LLM with everyday command-line tools to accomplish tasks like:</p><ul><li>Getting Linux help directly in the terminal without web searches</li><li>Extracting and embedding GitHub follower data for semantic search</li><li>Processing legislation like the "Big Beautiful Bill" for policy analysis</li><li>Generating visual progress reports from version control history</li></ul><p>The power of LLM lies in its ability to integrate with whatever tools you're already using in the command line, making AI augmentation accessible without requiring complex setups or subscriptions.</p>